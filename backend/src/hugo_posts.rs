use std::{fs::File, io::BufReader, path::Path};

use chrono::{DateTime, Utc};
use metrics::{counter, histogram};
use serde::{Deserialize, Serialize};
use sqlx::{postgres::PgRow, Error, FromRow, Row};
use tracing::instrument;
use url::Url;

/// Represents a blog post from the static site generator
/// This is the format of the json file that is generated by the static site generator
/// and contains the blog posts that might require publishing
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(rename_all = "camelCase")]
pub struct HugoBlogPost {
    /// Human-readable title - it should be a short sentence - single line
    pub title: String,
    /// The identifier for the post a slug from frontmatter or the filename
    /// if no slug is provided.
    ///
    /// This is used as main identifier in blog_posts database table
    pub slug: String,
    /// A short description of the post - it should be a single paragraph or two
    pub description: String,
    /// The date the post was created
    pub date: DateTime<Utc>,
    /// An image to use as the featured image for the blog post
    pub featured_image: Option<String>,
    /// List of tags for the post it will be mapped to mastodon tags
    pub tags: Option<Vec<String>>,
    /// The URL of the post itself
    pub url: Url,
}

impl FromRow<'_, PgRow> for HugoBlogPost {
    fn from_row(row: &PgRow) -> Result<Self, Error> {
        let title: String = row.try_get("title")?;
        let slug: String = row.try_get("slug")?;
        let description: String = row.try_get("description")?;
        let date: DateTime<Utc> = row.try_get("date")?;
        let featured_image: Option<String> = row.try_get("featured_image")?;
        let tags_str: Option<String> = row.try_get("tags")?;
        let url_str: String = row.try_get("url")?;

        // Parse the URL
        let url = Url::parse(&url_str).map_err(|e| Error::Decode(Box::new(e)))?;

        // Parse the tags if they exist
        let tags = tags_str.map(|s| s.split(',').map(String::from).collect());

        Ok(HugoBlogPost {
            title,
            slug,
            description,
            date,
            featured_image,
            tags,
            url,
        })
    }
}

type BlogPosts = Vec<HugoBlogPost>;

impl HugoBlogPost {
    /// Read and deserialize the blog posts from the filesystem file
    #[instrument(skip(path))]
    pub fn load_new_posts(path: impl AsRef<Path>) -> Result<BlogPosts, crate::error::Error> {
        let start_time = std::time::Instant::now();

        let file = File::open(path)?;
        let reader = BufReader::new(file);
        let blog_posts: BlogPosts = serde_json::from_reader(reader)?;

        counter!("blog_posts_loaded_total").increment(blog_posts.len() as u64);
        histogram!("blog_posts_load_duration_ms").record(start_time.elapsed().as_millis() as f64);

        Ok(blog_posts)
    }
}

pub struct BlogRepository {
    pub db: sqlx::PgPool,
}

impl BlogRepository {
    /// Create a new blog post entry in the database - called when a new blog post is present in
    /// json file from static site generator
    #[instrument(skip(self), fields(slug = %blog_post.slug))]
    pub async fn new_blog_entry(&self, blog_post: &HugoBlogPost) -> Result<(), Error> {
        let start_time = std::time::Instant::now();

        let tags_str = blog_post.tags.clone().map(|tags| tags.join(","));
        sqlx::query!(
            "INSERT INTO blog_posts (title, slug, description, date, featured_image, tags, url) VALUES ($1, $2, $3, $4, $5, $6, $7) ON CONFLICT(slug) DO UPDATE SET title = excluded.title, description = excluded.description, date = excluded.date, featured_image = excluded.featured_image, tags = excluded.tags, url = excluded.url",
            blog_post.title,
            blog_post.slug,
            blog_post.description,
            blog_post.date,
            blog_post.featured_image,
            tags_str,
            blog_post.url.to_string()
        )
        .execute(&self.db)
        .await?;

        counter!("blog_posts_processed_total").increment(1);
        histogram!("blog_database_query_duration_ms", "query" => "new_blog_entry")
            .record(start_time.elapsed().as_millis() as f64);

        Ok(())
    }
}
